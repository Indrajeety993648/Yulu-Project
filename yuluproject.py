# -*- coding: utf-8 -*-
"""YuluProject

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aWNT8kPjgcbCmWzmY8OUxnhTT17XvFMb

# **Problem Statement**

We have been given a dataset of the Count of rental bikes of Yulu along with datetime, atmospheric condition, and day type. We have to analyze attributes affecting the company's revenue and give feedback on conditions affecting it.

Importing required Python Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels
from scipy.special import comb
from scipy.stats import binom
from scipy.stats import norm,t
from scipy.stats import poisson, expon,geom, ttest_1samp, ttest_ind,ttest_ind_from_stats
from scipy.stats import shapiro, levene, kruskal, chi2, chi2_contingency
from statsmodels.graphics.gofplots import qqplot

!wget "https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/001/428/original/bike_sharing.csv?1642089089"

#Loading of the dataset
df=pd.read_csv("bike_sharing.csv?1642089089")
df

"""
**Observation on shape of data, data types of all the attributes, conversion of categorical attributes to 'category', missing value detection, statistical summary:**"""

#Checking of the shape of the data
df.shape

#Checking number of unique values in attributes
df.nunique()

#Checking the data types of all attributes
df.info()

#Converting datetime from object to datetime category
df["datetime"]=pd.to_datetime(df["datetime"])
df.info()

#Converting categorical variable to category type
df["season"]=df["season"].astype("object")
df["holiday"]=df["holiday"].astype("object")
df["workingday"]=df["workingday"].astype("object")
df["weather"]=df["weather"].astype("object")
df.info()

#Checking of missing values in the dataset
df.isnull().sum()

#Statistical summary of numeric variables in the dataset
df.describe()

#Description of Object type data in dataset
df.describe(include="object")

#Description of datetime type data in dataset
df.describe(include="datetime")

"""
**Univariate Analysis**"""

#distplot for temp attribute
sns.distplot(df["temp"])

#distplot for atemp attribute
sns.distplot(df["atemp"])

#distplot for humidity attribute
sns.distplot(df["humidity"])

#distplot for windspeed attribute
sns.distplot(df["windspeed"])

#distplot for count of casual users
sns.distplot(df["casual"])

#distplot for count of registered users
sns.distplot(df["registered"])

#distplot for total rental bikes including both casual and registered
sns.distplot(df["count"])

#histplot for temp attribute
sns.histplot(df["temp"])

#histplot for atemp attribute
sns.histplot(df["atemp"])

#histplot for humidity attribute
sns.histplot(df["humidity"])

#histplot for windspeed attribute
sns.histplot(df["windspeed"])

#histplot for count of casual users
sns.histplot(df["casual"])

#histplot for count of registered users
sns.histplot(df["registered"])

#histplot for count of total rental bikes including both registered and casual
sns.histplot(df["count"])

#boxplot for temp attribute
sns.boxplot(df["temp"])

#Boxplot for windspeed attribute
sns.boxplot(df["windspeed"])

#boxplot for humidity attribute
sns.boxplot(df["humidity"])

#boxplot for count of registered users
sns.boxplot(df["registered"])

#boxplot for count of casual users
sns.boxplot(df["casual"])

#boxplot for count of total rental bikes including both casual and registered users
sns.boxplot(df["count"])

#Countplot for seasons
sns.countplot(data=df,x="season")

#countplot for holidays categories
sns.countplot(data=df, x="holiday")

#countplot for working days and non working days
sns.countplot(data=df,x="workingday")

#countplot for weather types
sns.countplot(data=df,x="weather")

"""
**Bivariate Analysis**"""

#barplot between workingday and count to understand business based on workingday
sns.barplot(data=df, x="workingday", y="count")

#barplot between workingday and count to understand business based on holiday
sns.barplot(data=df, x="holiday", y="count")

#barplot between season and count to understand business based on season
sns.barplot(data=df, x="season", y="count")

#barplot between weather and count to understand business based on weather
sns.barplot(df, x="weather",y="count")

#Lineplot between humidity and count
sns.lineplot(df, x="humidity",y="count")

#boxplot between weather and count to understand business based on weather
sns.boxplot(df, x="weather", y="count")

#boxplot between season and count to understand business based on season
sns.boxplot(df,x="season", y="count")

#boxplot between workingday and count to understand business based on workingday
sns.boxplot(df,x="workingday", y="count")

#Pairplots in the dataframes having numeric datatype
sns.pairplot(df.loc[:,"temp":])

#Correlation between different attributes of dataframe
df.corr()

#Heatmap based on correlation between attributes
sns.heatmap(data=df.corr())

"""**Dataset Info**

datetime: It contains the date and time respondence to the given data. It ranges from 2011-01-01 to 2012-12-19.

season: It contains 4 values of the season that are spring, summer, fall, and winter

holiday: It gives whether a given day is a holiday or not.

working day: It gives whether the given day is a working day or a holiday or weekend

weather: It contains 4 different masked categories of weather

temp: It gives the temperature in Celsius at that moment, and its value ranges from 0.82 to 41.00.

atemp: It gives the feeling temperature in Celsius at that moment, and its value ranges from 0.76 to 45.45.

humidity: It gives the humidity at a given time, and its value ranges from 0.0 to 100.00

windspeed: It gives the values of windspeed at a given time, and its value ranges from 0.0 to 56.99

casual: It gives a count of casual users at a given time, and its value ranges from 0 to 367

registered: It gives a count of casual users at a given time, and its value ranges from 0 to 886

count: It gives a count of total rental bikes including both casual and registered, and its value ranges from 1 to 977.

Here Outliers are found by IQR method in casual, registered, and count columns, but as dropping or morphing of outliers may affect our statistical significance, so Its better to keep them in our data.

**2 Sample T-Test**
"""

#Filtering count based on working day
working_day_count= df.loc[df["workingday"]==1,"count"]
non_working_day_count=df.loc[df["workingday"]==0,"count"]

#Mean and Standard Deviation of count during working day
working_day_count.mean(), working_day_count.std()

#Mean and Standard Deviation of count during Non-working day
non_working_day_count.mean(), non_working_day_count.std()

"""Ho : mean of working day and non working day is same : mu1 = mu2

Ha : mean of working day is higher than non working day : mu1 > mu2
"""

#Let us set siginificance level 0.05, confidence level 95%
alpha=0.05

#Let we do t-test for 2 samples and find test_statistics and p-value
test_statistic, p_value = ttest_ind(working_day_count,non_working_day_count, alternative="greater")
test_statistic, p_value

#Decision based on p-value and significance level
if p_value < alpha:
    print("Reject Null Hypothesis Ho")
else:
    print("Fail to Reject Null Hypothesis Ho")

"""We have considered a confidence level of 95% in the Test.

The 2 Sample T-Test between the count attributes of the working day and the non-working day has been carried out and We found from the 2 Sample T-test that the means of both samples have no statistically significant difference.

**ANOVA Test**
"""

#Filtering count based on weather category
weather_1 = df.loc[df["weather"]==1,"count"]
weather_2 = df.loc[df["weather"]==2,"count"]
weather_3 = df.loc[df["weather"]==3,"count"]
weather_4 = df.loc[df["weather"]==4,"count"]

weather_4 #Only single value is there with weather category 4 so, We will not consider this category for ANOVA Test

"""We will do shapiro Test for checking whether our sample follows Gaussian Distribution or not

Null and Alternate Hypothesis for Shapiro Test

H0: The sample follows Gaussian Distribution

Ha: The sample does not follow Gaussian Distribution
"""

#Let us set siginificance level 0.05, confidence level 95%
alpha=0.05

#p-value calculation
test_statistics, p_value = shapiro(weather_1)
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, Sample does not follow Gaussian Distribution")
else:
    print("Fail to Reject Null Hypothesis, Sample follows Gaussian Distribution")

#p-value calculation
test_statistics, p_value = shapiro(weather_2)
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, Sample does not follow Gaussian Distribution")
else:
    print("Fail to Reject Null Hypothesis, Sample follows Gaussian Distribution")

#Let's check for normality based on q-q plot
qqplot(weather_1,line="s")
plt.show()
#Here Plot not matching with straight line so based on that we can say that sample |

#Let's check for normality based on q-q plot
qqplot(weather_2,line="s")
plt.show()
#Here Plot not matching with straight line so based on that we can say that sample

#Let's check for normality based on q-q plot
qqplot(weather_3,line="s")
plt.show()
#Here Plot not matching with straight line so based on that we can say that sample

"""We will do levene test to check whether variance of the samples are same or not

Null Hypothesis and Alternate Hypothesis for Levene Test

H0: Variances of the samples are same

Ha: Variances of the samples are not same
"""

#Let us set siginificance level 0.05, confidence level 95%
alpha=0.05

#p-value calculation
test_statistics, p_value=levene(weather_1,weather_2, weather_3)
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, Variances of the samples are not same")
else:
    print("Fail to Reject Null Hypothesis, Variances of the samples are same")

"""As we have done shapiro and Q-Q Plot for checking Normality and Levene Test for checking Variance.

We have found that Samples do not follow Gaussian Distribution and do not have similar variance. So we will go for Kruskal-Wallis Test

Null and Alternate Hypothesis for Kruskal Wallis Test

H0: mean of total rental bikes of different weathers are same

Ha: mean of total rental bikes of different weathers are not same
"""

#Let us set siginificance level 0.05, confidence level 95%
alpha=0.05

#p-value calculation
test_statistics,p_value=kruskal(weather_1,weather_2,weather_3)
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, mean of total rental bikes of different weathers are not same")
else:
    print("Fail to Reject Null Hypothesis, mean of total rental bikes of different weathers are same")

#Filtering count based on weather category
season_1 = df.loc[df["season"]==1,"count"]
season_2 = df.loc[df["season"]==2,"count"]
season_3 = df.loc[df["season"]==3,"count"]
season_4 = df.loc[df["season"]==4,"count"]

"""We will do shapiro Test for checking whether our sample follows Gaussian Distribution or not

Null and Alternate Hypothesis for Shapiro Test

H0: The sample follows Gaussian Distribution

Ha: The sample does not follow Gaussian Distribution
"""

#Let us set siginificance level 0.05, confidence level 95%
alpha=0.05

#p-value calculation
test_statistics, p_value = shapiro(season_1)
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, Sample does not follow Gaussian Distribution")
else:
    print("Fail to Reject Null Hypothesis, Sample follows Gaussian Distribution")

#p-value calculation
test_statistics, p_value = shapiro(season_2)
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, Sample does not follow Gaussian Distribution")
else:
    print("Fail to Reject Null Hypothesis, Sample follows Gaussian Distribution")

#p-value calculation
test_statistics, p_value = shapiro(season_3)
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, Sample does not follow Gaussian Distribution")
else:
    print("Fail to Reject Null Hypothesis, Sample follows Gaussian Distribution")

#p-value calculation
test_statistics, p_value = shapiro(season_4)
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, Sample does not follow Gaussian Distribution")
else:
    print("Fail to Reject Null Hypothesis, Sample follows Gaussian Distribution")

#Let's check for normality based on q-q plot
qqplot(season_1,line="s")
plt.show()
#Here Plot not matching with straight line so based on that we can say that sample does not follow normal distribution

#Let's check for normality based on q-q plot
qqplot(season_2,line="s")
plt.show()
#Here Plot not matching with straight line so based on that we can say that sample does not follow normal distribution

#Let's check for normality based on q-q plot
qqplot(season_3,line="s")
plt.show()
#Here Plot not matching with straight line so based on that we can say that sample does not follow normal distribution

#Let's check for normality based on q-q plot
qqplot(season_4,line="s")
plt.show()
#Here Plot not matching with straight line so based on that we can say that sample

"""We will do levene test to check whether variance of the samples are same or not

Null Hypothesis and Alternate Hypothesis for Levene Test

H0: Variances of the samples are same

Ha: Variances of the samples are not same
"""

#Let us set siginificance level 0.05, confidence level 95%
alpha=0.05

#p-value calculation
test_statistics, p_value=levene(season_1, season_2, season_3, season_4)
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, Variances of the samples are not same")
else:
    print("Fail to Reject Null Hypothesis, Variances of the samples are same")

"""As we have done shapiro and Q-Q Plot for checking Normality and Levene Test for checking Variance.

We have found that Samples do not follow Gaussian Distribution and do not have similar variance. So we will go for Kruskal-Wallis Test

Null and Alternate Hypothesis for Kruskal Wallis Test

H0: mean of total rental bikes of different seasons are same

Ha: mean of total rental bikes of different seasons are not same
"""

#p-value calculation
test_statistics,p_value=kruskal(season_1, season_2, season_3, season_4)
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, mean of total rental bikes of different seasons are not same")
else:
    print("Fail to Reject Null Hypothesis, mean of total rental bikes of different seasons are same")

"""We have considered a confidence level of 95% in the Test.

For the assumptions testing like the shapiro-wilk test, q-q plot, and levene test has also been done in the Jupyter Notebook.

As samples fail for normality tests and variance tests, we have carried out Kruskal Wallis Test.

From the Kruskal Walis Test, It can be said that the Means of total rental bikes for different weathers has a statistically significant difference.

From the Kruskal Walis Test, It can be said that the Means of total rental bikes for different seasons has a statistically significant difference.

# **Chi-square Test**
"""

#Creating Contingency table between categorical attributes weather and season
ws= pd.crosstab(df["weather"], df["season"])
ws

#Here in our contingency table there is value count of 1 and 0 for weather type 4
#we can not do chi-square test as minimum frequency to run chi-square test is 5
ws.loc[1:3,:]

"""Here For Chi-Square Test between weather and Season

Null and Alternate Hypothesis

H0: Seasons and weather are independent

Ha: Seasons and weather are dependent on each other
"""

#Let us set siginificance level 0.05, confidence level 95%
alpha=0.05

#p-value calculation
test_statistics,p_value, dof, exp=chi2_contingency(ws)
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, Seasons and weather are dependent on each other")
else:
    print("Fail to Reject Null Hypothesis, Seasons and weather are independent")

#p-value calculation
test_statistics,p_value, dof, exp=chi2_contingency(ws.loc[1:3,:])
print("p-value:", round(p_value,4))
if p_value < alpha:
    print("Reject Null Hypotheis, Seasons and weather are dependent on each other")
else:
    print("Fail to Reject Null Hypothesis, Seasons and weather are independent")

"""We have considered a confidence level of 95% in the Test.

From the Chi-Square Test, We can say that weather and season are depended on each other.
"""

corr_data = df.corr()
corr_data

plt.figure(figsize = (12, 8))
sns.heatmap(data = corr_data, cmap = 'Greens', annot = True, vmin = -1, vmax = 1)
plt.plot()

"""*  Very High Correlation (> 0.9) exists between columns [atemp, temp] and [count, registered]
*  High positively / negatively correlation (0.7 - 0.9) does not exist between any columns.

*   Low Positive correlation (0.3 - 0.5) exists between columns [count, temp], [count, atemp], [casual, atemp]
*  Negligible correlation exists between all other combinations of columns.

**Insights**

*   The data is given from Timestamp('2011-01-01 00:00:00') to Timestamp('2012-12-19 23:00:00'). The total time period for which the data is given is '718 days 23:00:00'.
*  Out of every 100 users, around 19 are casual users and 81 are registered users.


*   The mean total hourly count of rental bikes is 144 for the year 2011 and 239 for the year 2012. An annual growth rate of 65.41 % can be seen in the demand of electric vehicles on an hourly basis.
* There is a seasonal pattern in the count of rental bikes, with higher demand during the spring and summer months, a slight decline in the fall, and a further decrease in the winter months.
The average hourly count of rental bikes is the lowest in the month of January followed by February and March.


*  There is a distinct fluctuation in count throughout the day, with low counts during early morning hours, a sudden increase in the morning, a peak count in the afternoon, and a gradual decline in the evening and nighttime.
*   More than 80 % of the time, the temperature is less than 28 degrees celcius.


* More than 80 % of the time, the humidity value is greater than 40. Thus for most of the time, humidity level varies from optimum to too moist.  
*  More than 85 % of the total, windspeed data has a value of less than 20.


*  The hourly count of total rental bikes is the highest in the clear and cloudy weather, followed by the misty weather and rainy weather. There are very few records for extreme weather conditions.
* The mean hourly count of the total rental bikes is statistically similar for both working and non- working days.


*  There is statistically significant dependency of weather and season based on the hourly total number of bikes rented.
*  The hourly total number of rental bikes is statistically different for different weathers.
There is no statistically significant dependency of weather 1, 2, 3 on season based on the average hourly total number of bikes rented.

The hourly total number of rental bikes is statistically different for different seasons.

# Recommendations

During spring, Yulu should provide some discounts and offers to increase the use of rental bikes.

During weather of rain, The mean of total rental bikes is lower than others. As Yulu provides bike services, customers can't use it in rainy times. so Yulu should provide some roofs or cab services during this weather.

As humidity increases the total number of rental bikes decreases, so, Yulu should provide benefits during these humid days.

Yulu can increase the use of rental bikes by providing some city tour offers, events, or campaigns during non-working days.

Yulu can convert its casual users to registered users by providing some discounts or registration offers to convert casual users to registered users.

As mostly there is clear weather, Yulu should focus on the increase in total rental bikes during clear weather days.
"""

